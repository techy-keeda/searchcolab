{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRV304Fv3WePImC3RNsQfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techy-keeda/searchcolab/blob/main/Copy_of_StarGAN_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Official Github Implementation "
      ],
      "metadata": {
        "id": "YQazTPq7fS4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import torch, torchvision, cv2, scipy, tqdm\n",
        "\n",
        "# Installing necessary packages\n",
        "from google.colab import output\n",
        "!pip3 install opencv-python ffmpeg-python scikit-image\n",
        "!pip3 install pillow munch\n",
        "\n",
        "# Cloning the repository containing the StarGAN v2 code\n",
        "!git clone https://github.com/clovaai/stargan-v2.git\n",
        "\n",
        "# Changing the current working directory to the cloned repository\n",
        "%cd /content/stargan-v2\n",
        "\n",
        "# Running shell scripts to download necessary datasets and pre-trained networks\n",
        "!bash download.sh celeba-hq-dataset\n",
        "!bash download.sh pretrained-network-celeba-hq\n",
        "!bash download.sh wing\n",
        "\n",
        "# Clearing the output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "FcPSZpnoyy2A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"/content/stargan-v2/core/checkpoint.py\" with the actual path to the checkpoint.py file on your Google Drive\n",
        "file_path = \"/content/stargan-v2/core/checkpoint.py\"\n",
        "\n",
        "# Read the file\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Modify the desired line\n",
        "for i, line in enumerate(lines):\n",
        "    if '                module.module.load_state_dict(module_dict[name])' in line:\n",
        "        lines[i] = '                module.module.load_state_dict(module_dict[name], False)\\n'\n",
        "        break\n",
        "\n",
        "# Write the modified file back to disk\n",
        "with open(file_path, 'w') as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "print(\"File modified successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-BU3490edFZ",
        "outputId": "b013cd53-26c9-4cc6-820d-9e790f02cc51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File modified successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# !fusermount -u -z /content/gdrive"
      ],
      "metadata": {
        "id": "3Pzn2YKFlJaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/stargan-v2/assets/representative/celeba_hq/ref/female && ls | head -n 3 | xargs rm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8iS8bqHpk0s",
        "outputId": "d3ee6904-be68-4a41-e213-521961162cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "chdir: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/stargan-v2/assets/representative/celeba_hq/src/male/*\n",
        "# !rm -r /content/stargan-v2/assets/representative/celeba_hq/src/female/Untitled.jpg\n",
        "# !rm -r /content/stargan-v2/assets/representative/custom/female/*"
      ],
      "metadata": {
        "id": "os2spz3xzcUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/stargan-v2/data/celeba_hq/val/female/000168.jpg /content/"
      ],
      "metadata": {
        "id": "C0LQHknkITzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stargan-v2\n",
        "\n",
        "!python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
        "               --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
        "               --result_dir expr/results/celeba_hq \\\n",
        "               --src_dir assets/representative/celeba_hq/src \\\n",
        "               --ref_dir assets/representative/celeba_hq/ref           "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px_-lQw9jy4r",
        "outputId": "8475b4b4-9ae8-4880-8272-8397dfaebc5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stargan-v2\n",
            "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/celeba_hq/ref', result_dir='expr/results/celeba_hq', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/celeba_hq/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
            "Number of parameters of generator: 43467395\n",
            "Number of parameters of mapping_network: 2438272\n",
            "Number of parameters of style_encoder: 20916928\n",
            "Number of parameters of discriminator: 20852290\n",
            "Number of parameters of fan: 6333603\n",
            "Initializing generator...\n",
            "Initializing mapping_network...\n",
            "Initializing style_encoder...\n",
            "Initializing discriminator...\n",
            "Preparing DataLoader for the generation phase...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Preparing DataLoader for the generation phase...\n",
            "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
            "Working on expr/results/celeba_hq/reference.jpg...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "/content/stargan-v2/core/wing.py [line 424]\n",
        "\n",
        "for fname in fnames:\n",
        "    if os.path.isdir(os.path.join(input_dir, fname)) or fname.endswith('.ipynb_checkpoints'):\n",
        "        continue\n",
        "    image = Image.open(os.path.join(input_dir, fname)).convert('RGB')\n",
        "    x = transform(image).unsqueeze(0)\n",
        "    x_aligned = aligner.align(x)\n",
        "    save_image(x_aligned, 1, filename=os.path.join(output_dir, fname))\n",
        "    print('Saved the aligned image to %s...' % fname)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "uvob0uXyyrDq",
        "outputId": "0b3299d6-6682-4046-a83d-6cf1ecf2bde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor fname in fnames:\\n    if os.path.isdir(os.path.join(input_dir, fname)) or fname.endswith('.ipynb_checkpoints'):\\n        continue\\n    image = Image.open(os.path.join(input_dir, fname)).convert('RGB')\\n    x = transform(image).unsqueeze(0)\\n    x_aligned = aligner.align(x)\\n    save_image(x_aligned, 1, filename=os.path.join(output_dir, fname))\\n    print('Saved the aligned image to %s...' % fname)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stargan-v2\n",
        "!python main.py --mode align \\\n",
        "               --inp_dir assets/representative/custom/female \\\n",
        "               --out_dir /content/stargan-v2/assets/representative/celeba_hq/src/female"
      ],
      "metadata": {
        "id": "itcCaoos73BM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbc2aa7-03cb-46c1-8f94-64f232e741c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stargan-v2\n",
            "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='align', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='/content/stargan-v2/assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/celeba_hq/ref', result_dir='expr/results', resume_iter=0, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/celeba_hq/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
            "Number of parameters of generator: 43467395\n",
            "Number of parameters of mapping_network: 2438272\n",
            "Number of parameters of style_encoder: 20916928\n",
            "Number of parameters of discriminator: 20852290\n",
            "Number of parameters of fan: 6333603\n",
            "Initializing generator...\n",
            "Initializing mapping_network...\n",
            "Initializing style_encoder...\n",
            "Initializing discriminator...\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 182, in <module>\n",
            "    main(args)\n",
            "  File \"main.py\", line 78, in main\n",
            "    align_faces(args, args.inp_dir, args.out_dir)\n",
            "  File \"/content/stargan-v2/core/wing.py\", line 425, in align_faces\n",
            "    image = Image.open(os.path.join(input_dir, fname)).convert('RGB')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2843, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "IsADirectoryError: [Errno 21] Is a directory: 'assets/representative/custom/female/.ipynb_checkpoints'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test field"
      ],
      "metadata": {
        "id": "rciKlx0VUnz4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thh7H0FvUndM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "input_folder = '/content/stargan-v2/data/celeba_hq/train/male'  # replace with the path to your input folder\n",
        "output_folder = '/content/male'  # replace with the path to your output folder\n",
        "target_size = (128, 128)  # replace with the desired output size\n",
        "\n",
        "# create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# loop over all the images in the input folder\n",
        "for image_name in os.listdir(input_folder):\n",
        "    image_path = os.path.join(input_folder, image_name)\n",
        "\n",
        "    # open the image\n",
        "    with Image.open(image_path) as img:\n",
        "        # resize the image\n",
        "        img = img.resize(target_size)\n",
        "\n",
        "        # save the resized image to the output folder\n",
        "        output_path = os.path.join(output_folder, image_name)\n",
        "        img.save(output_path)\n",
        "\n",
        "print(\"Done resizing and saving images.\")"
      ],
      "metadata": {
        "id": "WUnV9lc14f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977bd400-4472-4200-bb5e-b36c9febc4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done resizing and saving images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from munch import Munch\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "\n",
        "def get_single_image_loader(image_path, img_size=256):\n",
        "    print('Preparing DataLoader for the generation phase...')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize([img_size, img_size]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image)\n",
        "    label = 0 # any integer\n",
        "    dataset = [(image, label)]\n",
        "    return data.DataLoader(dataset=dataset,\n",
        "                           batch_size=1,\n",
        "                           shuffle=False,\n",
        "                           num_workers=0,\n",
        "                           pin_memory=True)\n",
        "\n",
        "src = get_single_image_loader('/content/000168.jpg')\n",
        "ref = get_single_image_loader('/content/010987.jpg')\n",
        "loaders = Munch(src=src, ref=ref)"
      ],
      "metadata": {
        "id": "vGH5Cu2un4Y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96026ced-6dff-48de-bff3-f24b30e85c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing DataLoader for the generation phase...\n",
            "Preparing DataLoader for the generation phase...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(src,ref,loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZiXBwQAOPjo",
        "outputId": "9209f5d2-f06c-4072-d816-64cd3c22f427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f8243304fa0> <torch.utils.data.dataloader.DataLoader object at 0x7f8243304880> Munch({'src': <torch.utils.data.dataloader.DataLoader object at 0x7f8243304fa0>, 'ref': <torch.utils.data.dataloader.DataLoader object at 0x7f8243304880>})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stargan-v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ8-zbrfPaC2",
        "outputId": "836cbec9-4c1c-4e64-abec-0b5169b653e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stargan-v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# model arguments\n",
        "parser.add_argument('--img_size', type=int, default=256,\n",
        "                    help='Image resolution')\n",
        "parser.add_argument('--num_domains', type=int, default=2,\n",
        "                    help='Number of domains')\n",
        "parser.add_argument('--latent_dim', type=int, default=16,\n",
        "                    help='Latent vector dimension')\n",
        "parser.add_argument('--hidden_dim', type=int, default=512,\n",
        "                    help='Hidden dimension of mapping network')\n",
        "parser.add_argument('--style_dim', type=int, default=64,\n",
        "                    help='Style code dimension')\n",
        "\n",
        "# weight for objective functions\n",
        "parser.add_argument('--lambda_reg', type=float, default=1,\n",
        "                    help='Weight for R1 regularization')\n",
        "parser.add_argument('--lambda_cyc', type=float, default=1,\n",
        "                    help='Weight for cyclic consistency loss')\n",
        "parser.add_argument('--lambda_sty', type=float, default=1,\n",
        "                    help='Weight for style reconstruction loss')\n",
        "parser.add_argument('--lambda_ds', type=float, default=1,\n",
        "                    help='Weight for diversity sensitive loss')\n",
        "parser.add_argument('--ds_iter', type=int, default=100000,\n",
        "                    help='Number of iterations to optimize diversity sensitive loss')\n",
        "parser.add_argument('--w_hpf', type=float, default=1,\n",
        "                    help='weight for high-pass filtering')\n",
        "\n",
        "# training arguments\n",
        "parser.add_argument('--randcrop_prob', type=float, default=0.5,\n",
        "                    help='Probabilty of using random-resized cropping')\n",
        "parser.add_argument('--total_iters', type=int, default=100000,\n",
        "                    help='Number of total iterations')\n",
        "parser.add_argument('--resume_iter', type=int, default=0,\n",
        "                    help='Iterations to resume training/testing')\n",
        "parser.add_argument('--batch_size', type=int, default=8,\n",
        "                    help='Batch size for training')\n",
        "parser.add_argument('--val_batch_size', type=int, default=32,\n",
        "                    help='Batch size for validation')\n",
        "parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                    help='Learning rate for D, E and G')\n",
        "parser.add_argument('--f_lr', type=float, default=1e-6,\n",
        "                    help='Learning rate for F')\n",
        "parser.add_argument('--beta1', type=float, default=0.0,\n",
        "                    help='Decay rate for 1st moment of Adam')\n",
        "parser.add_argument('--beta2', type=float, default=0.99,\n",
        "                    help='Decay rate for 2nd moment of Adam')\n",
        "parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
        "                    help='Weight decay for optimizer')\n",
        "parser.add_argument('--num_outs_per_domain', type=int, default=10,\n",
        "                    help='Number of generated images per domain during sampling')\n",
        "\n",
        "# misc\n",
        "parser.add_argument('--mode', type=str, default='sample',\n",
        "                    help='This argument is used in solver')\n",
        "parser.add_argument('--num_workers', type=int, default=4,\n",
        "                    help='Number of workers used in DataLoader')\n",
        "parser.add_argument('--seed', type=int, default=777,\n",
        "                    help='Seed for random number generator')\n",
        "\n",
        "# directory for training\n",
        "parser.add_argument('--train_img_dir', type=str, default='data/celeba_hq/train',\n",
        "                    help='Directory containing training images')\n",
        "parser.add_argument('--val_img_dir', type=str, default='data/celeba_hq/val',\n",
        "                    help='Directory containing validation images')\n",
        "parser.add_argument('--sample_dir', type=str, default='expr/samples',\n",
        "                    help='Directory for saving generated images')\n",
        "parser.add_argument('--checkpoint_dir', type=str, default='expr/checkpoints',\n",
        "                    help='Directory for saving network checkpoints')\n",
        "\n",
        "# directory for calculating metrics\n",
        "parser.add_argument('--eval_dir', type=str, default='expr/eval',\n",
        "                    help='Directory for saving metrics, i.e., FID and LPIPS')\n",
        "\n",
        "# directory for testing\n",
        "parser.add_argument('--result_dir', type=str, default='expr/results',\n",
        "                    help='Directory for saving generated images and videos')\n",
        "parser.add_argument('--src_dir', type=str, default='assets/representative/celeba_hq/src',\n",
        "                    help='Directory containing input source images')\n",
        "parser.add_argument('--ref_dir', type=str, default='assets/representative/celeba_hq/ref',\n",
        "                    help='Directory containing input reference images')\n",
        "parser.add_argument('--inp_dir', type=str, default='assets/representative/custom/female',\n",
        "                    help='input directory when aligning faces')\n",
        "parser.add_argument('--out_dir', type=str, default='assets/representative/celeba_hq/src/female',\n",
        "                    help='output directory when aligning faces')\n",
        "\n",
        "# face alignment\n",
        "parser.add_argument('--wing_path', type=str, default='expr/checkpoints/wing.ckpt')\n",
        "parser.add_argument('--lm_path', type=str, default='expr/checkpoints/celeba_lm_mean.npz')\n",
        "\n",
        "# step size\n",
        "parser.add_argument('--print_every', type=int, default=10)\n",
        "parser.add_argument('--sample_every', type=int, default=5000)\n",
        "parser.add_argument('--save_every', type=int, default=10000)\n",
        "parser.add_argument('--eval_every', type=int, default=50000)\n",
        "\n",
        "args = parser.parse_args()\n",
        "# solver = Solver(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "kbZRDm-KWeoV",
        "outputId": "8eb8f44a-77d6-478e-cfce-2ed7a232c54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--img_size IMG_SIZE]\n",
            "                             [--num_domains NUM_DOMAINS]\n",
            "                             [--latent_dim LATENT_DIM]\n",
            "                             [--hidden_dim HIDDEN_DIM] [--style_dim STYLE_DIM]\n",
            "                             [--lambda_reg LAMBDA_REG]\n",
            "                             [--lambda_cyc LAMBDA_CYC]\n",
            "                             [--lambda_sty LAMBDA_STY] [--lambda_ds LAMBDA_DS]\n",
            "                             [--ds_iter DS_ITER] [--w_hpf W_HPF]\n",
            "                             [--randcrop_prob RANDCROP_PROB]\n",
            "                             [--total_iters TOTAL_ITERS]\n",
            "                             [--resume_iter RESUME_ITER]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--val_batch_size VAL_BATCH_SIZE] [--lr LR]\n",
            "                             [--f_lr F_LR] [--beta1 BETA1] [--beta2 BETA2]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--num_outs_per_domain NUM_OUTS_PER_DOMAIN]\n",
            "                             [--mode MODE] [--num_workers NUM_WORKERS]\n",
            "                             [--seed SEED] [--train_img_dir TRAIN_IMG_DIR]\n",
            "                             [--val_img_dir VAL_IMG_DIR]\n",
            "                             [--sample_dir SAMPLE_DIR]\n",
            "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
            "                             [--eval_dir EVAL_DIR] [--result_dir RESULT_DIR]\n",
            "                             [--src_dir SRC_DIR] [--ref_dir REF_DIR]\n",
            "                             [--inp_dir INP_DIR] [--out_dir OUT_DIR]\n",
            "                             [--wing_path WING_PATH] [--lm_path LM_PATH]\n",
            "                             [--print_every PRINT_EVERY]\n",
            "                             [--sample_every SAMPLE_EVERY]\n",
            "                             [--save_every SAVE_EVERY]\n",
            "                             [--eval_every EVAL_EVERY]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-d07143fd-0fcb-4de9-a0fc-1702c0e830f2.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaders.src)\n",
        "from core.solver import Solver\n",
        "loaders = Munch(src=src, ref=ref)\n",
        "Solver.sample(loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "wLfnD1RfQai7",
        "outputId": "8c6da34b-590a-46e7-8a8b-17d2668c6572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f8243304fa0>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d9c940c24b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sample() missing 1 required positional argument: 'loaders'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join as ospj\n",
        "from munch import Munch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from core.model import build_model\n",
        "from core.checkpoint import CheckpointIO\n",
        "from core.data_loader import InputFetcher\n",
        "import core.utils as utils\n",
        "\n",
        "\n",
        "\n",
        "class Solver(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.nets, self.nets_ema = build_model(args)\n",
        "        # below setattrs are to make networks be children of Solver, e.g., for self.to(self.device)\n",
        "        for name, module in self.nets.items():\n",
        "            utils.print_network(module, name)\n",
        "            setattr(self, name, module)\n",
        "        for name, module in self.nets_ema.items():\n",
        "            setattr(self, name + '_ema', module)\n",
        "\n",
        "        self.ckptios = [CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), data_parallel=True, **self.nets_ema)]\n",
        "\n",
        "    def _load_checkpoint(self, step):\n",
        "        for ckptio in self.ckptios:\n",
        "            ckptio.load(step)\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, loaders):\n",
        "        args = self.args\n",
        "        nets_ema = self.nets_ema\n",
        "        os.makedirs(args.result_dir, exist_ok=True)\n",
        "        self._load_checkpoint(args.resume_iter)\n",
        "\n",
        "        src = next(InputFetcher(loaders.src, None, args.latent_dim, 'test'))\n",
        "        ref = next(InputFetcher(loaders.ref, None, args.latent_dim, 'test'))\n",
        "\n",
        "        fname = ospj(args.result_dir, 'reference.jpg')\n",
        "        print('Working on {}...'.format(fname))\n",
        "        utils.translate_using_reference(nets_ema, args, src.x, ref.x, ref.y, fname)\n",
        "\n",
        "Solver.sample(loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "KQYAf6tMORik",
        "outputId": "ffffcf67-5046-446e-a815-76e65a2a0d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-278df69f9535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_using_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnets_ema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mSolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sample() missing 1 required positional argument: 'loaders'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11tlWQ1tWBJV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}